{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Feature Engineering Home Page](https://www.kaggle.com/learn/feature-engineering)**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this exercise you'll apply more advanced encodings to encode the categorical variables ito improve your classifier model. The encodings you will implement are:\n",
    "\n",
    "- Count Encoding\n",
    "- Target Encoding\n",
    "- Leave-one-out Encoding\n",
    "- CatBoost Encoding\n",
    "- Feature embedding with SVD \n",
    "\n",
    "You'll refit the classifier after each encoding to check its performance on hold-out data. First, run the next cell to repeat the work you did in the last exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/pyarrow/pandas_compat.py:707: FutureWarning: .labels was deprecated in version 0.24.0. Use .codes instead.\n",
      "  labels = getattr(columns, 'labels', None) or [\n",
      "/opt/conda/lib/python3.6/site-packages/pyarrow/pandas_compat.py:734: FutureWarning: the 'labels' keyword is deprecated, use 'codes' instead\n",
      "  return pd.MultiIndex(levels=new_levels, labels=labels, names=columns.names)\n",
      "/opt/conda/lib/python3.6/site-packages/pyarrow/pandas_compat.py:751: FutureWarning: .labels was deprecated in version 0.24.0. Use .codes instead.\n",
      "  labels, = index.labels\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing, metrics\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Set up code checking\n",
    "# This can take a few seconds, thanks for your patience\n",
    "from learntools.core import binder\n",
    "binder.bind(globals())\n",
    "from learntools.feature_engineering.ex2 import *\n",
    "\n",
    "clicks = pd.read_parquet('../input/feature-engineering-data/baseline_data.pqt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I'll define a couple functions to help test the new encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_splits(dataframe, valid_fraction=0.1):\n",
    "    \"\"\" Splits a dataframe into train, validation, and test sets. First, orders by \n",
    "        the column 'click_time'. Set the size of the validation and test sets with\n",
    "        the valid_fraction keyword argument.\n",
    "    \"\"\"\n",
    "\n",
    "    dataframe = dataframe.sort_values('click_time')\n",
    "    valid_rows = int(len(dataframe) * valid_fraction)\n",
    "    train = dataframe[:-valid_rows * 2]\n",
    "    # valid size == test size, last two sections of the data\n",
    "    valid = dataframe[-valid_rows * 2:-valid_rows]\n",
    "    test = dataframe[-valid_rows:]\n",
    "    \n",
    "    return train, valid, test\n",
    "\n",
    "def train_model(train, valid, test=None, feature_cols=None):\n",
    "    if feature_cols is None:\n",
    "        feature_cols = train.columns.drop(['click_time', 'attributed_time',\n",
    "                                           'is_attributed'])\n",
    "    dtrain = lgb.Dataset(train[feature_cols], label=train['is_attributed'])\n",
    "    dvalid = lgb.Dataset(valid[feature_cols], label=valid['is_attributed'])\n",
    "    \n",
    "    param = {'num_leaves': 64, 'objective': 'binary', \n",
    "             'metric': 'auc', 'seed': 7}\n",
    "    num_round = 1000\n",
    "    print(\"Training model!\")\n",
    "    bst = lgb.train(param, dtrain, num_round, valid_sets=[dvalid], \n",
    "                    early_stopping_rounds=20, verbose_eval=False)\n",
    "    \n",
    "    valid_pred = bst.predict(valid[feature_cols])\n",
    "    valid_score = metrics.roc_auc_score(valid['is_attributed'], valid_pred)\n",
    "    print(f\"Validation AUC score: {valid_score}\")\n",
    "    \n",
    "    if test is not None: \n",
    "        test_pred = bst.predict(test[feature_cols])\n",
    "        test_score = metrics.roc_auc_score(test['is_attributed'], test_pred)\n",
    "        return bst, valid_score, test_score\n",
    "    else:\n",
    "        return bst, valid_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this cell to get a baseline score. If your encodings do better than this, you can keep them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline model\n",
      "Training model!\n",
      "Validation AUC score: 0.9622743228943659\n"
     ]
    }
   ],
   "source": [
    "print(\"Baseline model\")\n",
    "train, valid, test = get_data_splits(clicks)\n",
    "_ = train_model(train, valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Categorical encodings and leakage\n",
    "\n",
    "These encodings are all based on statistics calculated from the dataset like counts and means. Considering this, what data should you be using to calculate the encodings?\n",
    "\n",
    "Uncomment the following line after you've decided your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 3, \"questionType\": 4, \"learnTutorialId\": 271, \"questionId\": \"1_LeakageQuestion\", \"learnToolsVersion\": \"0.3.2\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#33cc99\">Solution:</span> You should calculate the encodings from the training set only. If you include data from the validation and test sets into the encodings, you'll overestimate the model's performance. You should in general be vigilant to avoid leakage, that is, including any information from the validation and test sets into the model. For a review on this topic, see our lesson on [data leakage](https://www.kaggle.com/alexisbcook/data-leakage)"
      ],
      "text/plain": [
       "Solution: You should calculate the encodings from the training set only. If you include data from the validation and test sets into the encodings, you'll overestimate the model's performance. You should in general be vigilant to avoid leakage, that is, including any information from the validation and test sets into the model. For a review on this topic, see our lesson on [data leakage](https://www.kaggle.com/alexisbcook/data-leakage)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "q_1.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Count encodings\n",
    "\n",
    "Here, encode the categorical features `['ip', 'app', 'device', 'os', 'channel']` using the count of each value in the data set. Using `CountEncoder` from the `category_encoders` library, fit the encoding using the categorical feature columns defined in `cat_features`. Then apply the encodings to the train and validation sets, adding them as new columns with names suffixed `\"_count\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.2, \"interactionType\": 1, \"questionType\": 1, \"learnTutorialId\": 271, \"questionId\": \"2_CountEncodings\", \"learnToolsVersion\": \"0.3.2\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#33cc33\">Correct</span>"
      ],
      "text/plain": [
       "Correct"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ip  app  device  os  channel          click_time      attributed_time  \\\n",
      "0   27226    3       1  13      120 2017-11-06 15:13:23                 None   \n",
      "1  110007   35       1  13       10 2017-11-06 15:41:07  2017-11-07 08:17:19   \n",
      "2    1047    6       1  13      157 2017-11-06 15:42:32                 None   \n",
      "3   76270    3       1  13      120 2017-11-06 15:56:17                 None   \n",
      "4   57862    3       1  13      120 2017-11-06 15:57:01                 None   \n",
      "\n",
      "   is_attributed  day  hour  minute  second  \n",
      "0              0    6    15      13      23  \n",
      "1              1    6    15      41       7  \n",
      "2              0    6    15      42      32  \n",
      "3              0    6    15      56      17  \n",
      "4              0    6    15      57       1  \n",
      "       ip  app  device  os  channel          click_time      attributed_time  \\\n",
      "0   27226    3       1  13      120 2017-11-06 15:13:23                 None   \n",
      "1  110007   35       1  13       10 2017-11-06 15:41:07  2017-11-07 08:17:19   \n",
      "2    1047    6       1  13      157 2017-11-06 15:42:32                 None   \n",
      "3   76270    3       1  13      120 2017-11-06 15:56:17                 None   \n",
      "4   57862    3       1  13      120 2017-11-06 15:57:01                 None   \n",
      "\n",
      "   is_attributed  day  hour  minute  second  ip_count  app_count  \\\n",
      "0              0    6    15      13      23        68     292254   \n",
      "1              1    6    15      41       7         4      60114   \n",
      "2              0    6    15      42      32       118      19564   \n",
      "3              0    6    15      56      17        29     292254   \n",
      "4              0    6    15      57       1        31     292254   \n",
      "\n",
      "   device_count  os_count  channel_count  \n",
      "0       1648091    370652          26760  \n",
      "1       1648091    370652          41256  \n",
      "2       1648091    370652          31221  \n",
      "3       1648091    370652          26760  \n",
      "4       1648091    370652          26760  \n"
     ]
    }
   ],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "cat_features = ['ip', 'app', 'device', 'os', 'channel']\n",
    "train, valid, test = get_data_splits(clicks)\n",
    "\n",
    "# Create the count encoder\n",
    "count_enc = ce.CountEncoder(cols=cat_features)\n",
    "\n",
    "# Learn encoding from the training set\n",
    "count_enc.fit(train[cat_features])\n",
    "\n",
    "# Apply encoding to the train and validation sets as new columns\n",
    "# Make sure to add `_count` as a suffix to the new columns\n",
    "train_encoded = train.join(count_enc.transform(train[cat_features]).add_suffix('_count'))\n",
    "valid_encoded = valid.join(count_enc.transform(valid[cat_features]).add_suffix('_count'))\n",
    "\n",
    "q_2.check()\n",
    "print(train.head())\n",
    "print(train_encoded.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 2, \"questionType\": 1, \"learnTutorialId\": 271, \"questionId\": \"2_CountEncodings\", \"learnToolsVersion\": \"0.3.2\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#3366cc\">Hint:</span> CountEncoder works like scikit-learn classes with a `.fit` method to calculate counts and a `.transform` method to apply the encoding. You can join two dataframes with the same index using `.join` and add suffixes to columns names with `.add_suffix`"
      ],
      "text/plain": [
       "Hint: CountEncoder works like scikit-learn classes with a `.fit` method to calculate counts and a `.transform` method to apply the encoding. You can join two dataframes with the same index using `.join` and add suffixes to columns names with `.add_suffix`"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 3, \"questionType\": 1, \"learnTutorialId\": 271, \"questionId\": \"2_CountEncodings\", \"learnToolsVersion\": \"0.3.2\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#33cc99\">Solution:</span> \n",
       "```python\n",
       "\n",
       "    # Create the count encoder\n",
       "    count_enc = CountEncoder(cols=cat_features)\n",
       "\n",
       "    # Learn encoding from the training set\n",
       "    count_enc.fit(train[cat_features])\n",
       "\n",
       "    # Apply encoding to the train and validation sets\n",
       "    train_encoded = train.join(count_enc.transform(train[cat_features]).add_suffix('_count'))\n",
       "    valid_encoded = valid.join(count_enc.transform(valid[cat_features]).add_suffix('_count'))\n",
       "    \n",
       "```"
      ],
      "text/plain": [
       "Solution: \n",
       "```python\n",
       "\n",
       "    # Create the count encoder\n",
       "    count_enc = CountEncoder(cols=cat_features)\n",
       "\n",
       "    # Learn encoding from the training set\n",
       "    count_enc.fit(train[cat_features])\n",
       "\n",
       "    # Apply encoding to the train and validation sets\n",
       "    train_encoded = train.join(count_enc.transform(train[cat_features]).add_suffix('_count'))\n",
       "    valid_encoded = valid.join(count_enc.transform(valid[cat_features]).add_suffix('_count'))\n",
       "    \n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Uncomment if you need some guidance\n",
    "q_2.hint()\n",
    "q_2.solution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model!\n",
      "Validation AUC score: 0.9653051135205329\n"
     ]
    }
   ],
   "source": [
    "# Train the model on the encoded datasets\n",
    "# This can take around 30 seconds to complete\n",
    "_ = train_model(train_encoded, valid_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count encoding improved our model's score!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Why is count encoding effective?\n",
    "At first glance, it could be surprising that Count Encoding helps make accurate models. \n",
    "Why do you think is count encoding is a good idea, or how does it improve the model score?\n",
    "\n",
    "Uncomment the following line after you've decided your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 3, \"questionType\": 4, \"learnTutorialId\": 271, \"questionId\": \"3_CountEncodingEffectiveness\", \"learnToolsVersion\": \"0.3.2\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#33cc99\">Solution:</span> \n",
       "    Rare values tend to have similar counts (with values like 1 or 2), so you can classify rare \n",
       "    values together at prediction time. Common values with large counts are unlikely to have \n",
       "    the same exact count as other values. So, the common/important values get their own \n",
       "    grouping.\n",
       "    "
      ],
      "text/plain": [
       "Solution: \n",
       "    Rare values tend to have similar counts (with values like 1 or 2), so you can classify rare \n",
       "    values together at prediction time. Common values with large counts are unlikely to have \n",
       "    the same exact count as other values. So, the common/important values get their own \n",
       "    grouping.\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "q_3.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Target encoding\n",
    "\n",
    "Here you'll try some supervised encodings that use the labels (the targets) to transform categorical features. The first one is target encoding. Create the target encoder from the `category_encoders` library. Then, learn the encodings from the training dataset, apply the encodings to all the datasets and retrain the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.2, \"interactionType\": 1, \"questionType\": 1, \"learnTutorialId\": 271, \"questionId\": \"4_TargetEncodings\", \"learnToolsVersion\": \"0.3.2\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#33cc33\">Correct</span>"
      ],
      "text/plain": [
       "Correct"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ip  app  device  os  channel          click_time      attributed_time  \\\n",
      "0   27226    3       1  13      120 2017-11-06 15:13:23                 None   \n",
      "1  110007   35       1  13       10 2017-11-06 15:41:07  2017-11-07 08:17:19   \n",
      "2    1047    6       1  13      157 2017-11-06 15:42:32                 None   \n",
      "3   76270    3       1  13      120 2017-11-06 15:56:17                 None   \n",
      "4   57862    3       1  13      120 2017-11-06 15:57:01                 None   \n",
      "\n",
      "   is_attributed  day  hour  minute  second  \n",
      "0              0    6    15      13      23  \n",
      "1              1    6    15      41       7  \n",
      "2              0    6    15      42      32  \n",
      "3              0    6    15      56      17  \n",
      "4              0    6    15      57       1  \n",
      "       ip  app  device  os  channel          click_time      attributed_time  \\\n",
      "0   27226    3       1  13      120 2017-11-06 15:13:23                 None   \n",
      "1  110007   35       1  13       10 2017-11-06 15:41:07  2017-11-07 08:17:19   \n",
      "2    1047    6       1  13      157 2017-11-06 15:42:32                 None   \n",
      "3   76270    3       1  13      120 2017-11-06 15:56:17                 None   \n",
      "4   57862    3       1  13      120 2017-11-06 15:57:01                 None   \n",
      "\n",
      "   is_attributed  day  hour  minute  second  ip_target  app_target  \\\n",
      "0              0    6    15      13      23   0.073529    0.028328   \n",
      "1              1    6    15      41       7   0.247523    0.995841   \n",
      "2              0    6    15      42      32   0.135593    0.009252   \n",
      "3              0    6    15      56      17   0.103448    0.028328   \n",
      "4              0    6    15      57       1   0.096774    0.028328   \n",
      "\n",
      "   device_target  os_target  channel_target  \n",
      "0       0.152087   0.138712        0.034043  \n",
      "1       0.152087   0.138712        0.950262  \n",
      "2       0.152087   0.138712        0.019378  \n",
      "3       0.152087   0.138712        0.034043  \n",
      "4       0.152087   0.138712        0.034043  \n"
     ]
    }
   ],
   "source": [
    "cat_features = ['ip', 'app', 'device', 'os', 'channel']\n",
    "train, valid, test = get_data_splits(clicks)\n",
    "\n",
    "# Create the target encoder. You can find this easily by using tab completion.\n",
    "# Start typing ce. the press Tab to bring up a list of classes and functions.\n",
    "target_enc = ce.TargetEncoder(cols=cat_features)\n",
    "\n",
    "# Learn encoding from the training set. Use the 'is_attributed' column as the target.\n",
    "target_enc.fit(train[cat_features], train['is_attributed'])\n",
    "\n",
    "# Apply encoding to the train and validation sets as new columns\n",
    "# Make sure to add `_target` as a suffix to the new columns\n",
    "train_encoded = train.join(target_enc.transform(train[cat_features]).add_suffix('_target'))\n",
    "valid_encoded = valid.join(target_enc.transform(valid[cat_features]).add_suffix('_target'))\n",
    "\n",
    "q_4.check()\n",
    "print(train.head())\n",
    "print(train_encoded.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 2, \"questionType\": 1, \"learnTutorialId\": 271, \"questionId\": \"4_TargetEncodings\", \"learnToolsVersion\": \"0.3.2\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#3366cc\">Hint:</span> TargetEncoder works like scikit-learn classes with a `.fit` method to learn the encoding and a `.transform` method to apply the encoding. Also note that you'll need to tell it which columns are categorical variables."
      ],
      "text/plain": [
       "Hint: TargetEncoder works like scikit-learn classes with a `.fit` method to learn the encoding and a `.transform` method to apply the encoding. Also note that you'll need to tell it which columns are categorical variables."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 3, \"questionType\": 1, \"learnTutorialId\": 271, \"questionId\": \"4_TargetEncodings\", \"learnToolsVersion\": \"0.3.2\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#33cc99\">Solution:</span> \n",
       "```python\n",
       "\n",
       "    # Have to tell it which features are categorical when they aren't strings\n",
       "    target_enc = ce.TargetEncoder(cols=cat_features)\n",
       "\n",
       "    # Learn encoding from the training set\n",
       "    target_enc.fit(train[cat_features], train['is_attributed'])\n",
       "\n",
       "    # Apply encoding to the train and validation sets\n",
       "    train_encoded = train.join(target_enc.transform(train[cat_features]).add_suffix('_target'))\n",
       "    valid_encoded = valid.join(target_enc.transform(valid[cat_features]).add_suffix('_target'))\n",
       "    \n",
       "```"
      ],
      "text/plain": [
       "Solution: \n",
       "```python\n",
       "\n",
       "    # Have to tell it which features are categorical when they aren't strings\n",
       "    target_enc = ce.TargetEncoder(cols=cat_features)\n",
       "\n",
       "    # Learn encoding from the training set\n",
       "    target_enc.fit(train[cat_features], train['is_attributed'])\n",
       "\n",
       "    # Apply encoding to the train and validation sets\n",
       "    train_encoded = train.join(target_enc.transform(train[cat_features]).add_suffix('_target'))\n",
       "    valid_encoded = valid.join(target_enc.transform(valid[cat_features]).add_suffix('_target'))\n",
       "    \n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Uncomment these if you need some guidance\n",
    "q_4.hint()\n",
    "q_4.solution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model!\n",
      "Validation AUC score: 0.9540530347873288\n"
     ]
    }
   ],
   "source": [
    "_ = train_model(train_encoded, valid_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Try removing IP encoding\n",
    "\n",
    "Try leaving `ip` out of the encoded features and retrain the model with target encoding again. You should find that the score increases and is above the baseline score! Why do you think the score is below baseline when we encode the IP address but above baseline when we don't?\n",
    "\n",
    "Uncomment the following line after you've decided your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 3, \"questionType\": 4, \"learnTutorialId\": 271, \"questionId\": \"5_RemoveIPEncoding\", \"learnToolsVersion\": \"0.3.2\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#33cc99\">Solution:</span> \n",
       "    Target encoding attempts to measure the population mean of the target for each \n",
       "    level in a categorical feature. This means when there is less data per level, the \n",
       "    estimated mean will be further away from the \"true\" mean, there will be more variance. \n",
       "    There is little data per IP address so it's likely that the estimates are much noisier\n",
       "    than for the other features. The model will rely heavily on this feature since it is \n",
       "    extremely predictive. This causes it to make fewer splits on other features, and those\n",
       "    features are fit on just the errors left over accounting for IP address. So, the \n",
       "    model will perform very poorly when seeing new IP addresses that weren't in the \n",
       "    training data (which is likely most new data). Going forward, we'll leave out the IP feature when trying\n",
       "    different encodings.\n",
       "    "
      ],
      "text/plain": [
       "Solution: \n",
       "    Target encoding attempts to measure the population mean of the target for each \n",
       "    level in a categorical feature. This means when there is less data per level, the \n",
       "    estimated mean will be further away from the \"true\" mean, there will be more variance. \n",
       "    There is little data per IP address so it's likely that the estimates are much noisier\n",
       "    than for the other features. The model will rely heavily on this feature since it is \n",
       "    extremely predictive. This causes it to make fewer splits on other features, and those\n",
       "    features are fit on just the errors left over accounting for IP address. So, the \n",
       "    model will perform very poorly when seeing new IP addresses that weren't in the \n",
       "    training data (which is likely most new data). Going forward, we'll leave out the IP feature when trying\n",
       "    different encodings.\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "q_5.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) CatBoost Encoding\n",
    "\n",
    "The CatBoost encoder is supposed to working well with the LightGBM model. Encode the categorical features with `CatBoostEncoder` and train the model on the encoded data again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.2, \"interactionType\": 1, \"questionType\": 1, \"learnTutorialId\": 271, \"questionId\": \"6_CatBoostEncodings\", \"learnToolsVersion\": \"0.3.2\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#33cc33\">Correct</span>"
      ],
      "text/plain": [
       "Correct"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train, valid, test = get_data_splits(clicks)\n",
    "\n",
    "# Create the CatBoost encoder\n",
    "cat_features = ['app', 'device', 'os', 'channel']\n",
    "cb_enc = ce.CatBoostEncoder(cols=cat_features, random_state=7)\n",
    "\n",
    "# Learn encoding from the training set\n",
    "cb_enc.fit(train[cat_features], train['is_attributed'])\n",
    "\n",
    "# Apply encoding to the train and validation sets as new columns\n",
    "# Make sure to add `_cb` as a suffix to the new columns\n",
    "train_encoded = train.join(cb_enc.transform(train[cat_features]).add_suffix('_cb'))\n",
    "valid_encoded = valid.join(cb_enc.transform(valid[cat_features]).add_suffix('_cb'))\n",
    "q_6.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 2, \"questionType\": 1, \"learnTutorialId\": 271, \"questionId\": \"6_CatBoostEncodings\", \"learnToolsVersion\": \"0.3.2\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#3366cc\">Hint:</span> CatBoostEncoder works like scikit-learn classes with a `.fit` method to learn the encoding and a `.transform` method to apply the encoding. Also note that you'll need to tell it which columns are categorical variables."
      ],
      "text/plain": [
       "Hint: CatBoostEncoder works like scikit-learn classes with a `.fit` method to learn the encoding and a `.transform` method to apply the encoding. Also note that you'll need to tell it which columns are categorical variables."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 3, \"questionType\": 1, \"learnTutorialId\": 271, \"questionId\": \"6_CatBoostEncodings\", \"learnToolsVersion\": \"0.3.2\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#33cc99\">Solution:</span> \n",
       "```python\n",
       "\n",
       "    # Have to tell it which features are categorical when they aren't strings\n",
       "    cb_enc = ce.CatBoostEncoder(cols=cat_features, random_state=7)\n",
       "\n",
       "    # Learn encoding from the training set\n",
       "    cb_enc.fit(train[cat_features], train['is_attributed'])\n",
       "\n",
       "    # Apply encoding to the train and validation sets\n",
       "    train_encoded = train.join(cb_enc.transform(train[cat_features]).add_suffix('_cb'))\n",
       "    valid_encoded = valid.join(cb_enc.transform(valid[cat_features]).add_suffix('_cb'))\n",
       "    \n",
       "```"
      ],
      "text/plain": [
       "Solution: \n",
       "```python\n",
       "\n",
       "    # Have to tell it which features are categorical when they aren't strings\n",
       "    cb_enc = ce.CatBoostEncoder(cols=cat_features, random_state=7)\n",
       "\n",
       "    # Learn encoding from the training set\n",
       "    cb_enc.fit(train[cat_features], train['is_attributed'])\n",
       "\n",
       "    # Apply encoding to the train and validation sets\n",
       "    train_encoded = train.join(cb_enc.transform(train[cat_features]).add_suffix('_cb'))\n",
       "    valid_encoded = valid.join(cb_enc.transform(valid[cat_features]).add_suffix('_cb'))\n",
       "    \n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Uncomment these if you need some guidance\n",
    "q_6.hint()\n",
    "q_6.solution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model!\n",
      "Validation AUC score: 0.9622743228943659\n"
     ]
    }
   ],
   "source": [
    "_ = train_model(train, valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CatBoost encodings work the best, so we'll keep those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = cb_enc.transform(clicks[cat_features])\n",
    "for col in encoded:\n",
    "    clicks.insert(len(clicks.columns), col + '_cb', encoded[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keep Going\n",
    "\n",
    "Now you are ready to **[generating completely new features](https://www.kaggle.com/matleonard/feature-generation)** from the data itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**[Feature Engineering Home Page](https://www.kaggle.com/learn/feature-engineering)**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "*Have questions or comments? Visit the [Learn Discussion forum](https://www.kaggle.com/learn-forum) to chat with other Learners.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
